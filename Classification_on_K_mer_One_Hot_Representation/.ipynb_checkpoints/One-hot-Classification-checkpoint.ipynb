{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CB7qktVu0Q6Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from itertools import permutations,combinations_with_replacement\n",
    "\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D, Input, concatenate\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlQxdag40Y14"
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('Test_gisaid_LS.csv')\n",
    "df_train=pd.read_csv('Train_gisaid_LS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ldqy4AXt0wfT",
    "outputId": "47ac18f8-e4eb-4422-ab6f-b214823e9d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8110\n"
     ]
    }
   ],
   "source": [
    "train_sequences=list(df_train[\"Sequence\"])\n",
    "y_indicator=list(df_train[\"Indicator\"])\n",
    "print(len(train_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rbqZRlHi1GXE",
    "outputId": "c7cfa080-1897-4f46-ecf6-e2bb7fc231fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "K_MER_LENGTH = 3 \n",
    "NUMBER_OF_K_MERS=np.power(4,K_MER_LENGTH)\n",
    "print(NUMBER_OF_K_MERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Cck-z4OlJQ5"
   },
   "outputs": [],
   "source": [
    "def get_motifs(length,seq):\n",
    "    #print(length)\n",
    "    (d,index) = ({}, 0)\n",
    "    permitted_list = ['A','C','G','T']\n",
    "    # all_sequences_k_mer = []\n",
    "    # for seq in sequences_list:\n",
    "    seq_k_mer_list = []\n",
    "    for i in range(0, len(seq)-length+1):\n",
    "        flag=0\n",
    "        word = seq[i:i+length]\n",
    "        #print(\"here\")\n",
    "        #print(word)\n",
    "        #print(\"\\n\")\n",
    "        for letter in word:\n",
    "            if letter not in permitted_list:\n",
    "                flag=1\n",
    "        if(flag == 1):\n",
    "            continue\n",
    "        seq_k_mer_list.append(word)\n",
    "        \n",
    "        # all_sequences_k_mer.append(seq_k_mer_list)\n",
    "    return seq_k_mer_list\n",
    "\n",
    "\n",
    "\n",
    "def get_motifs_V2(length):\n",
    "    lst = ['A','C','G','T','N']\n",
    "    # els = [list(x) for x in itertools.combinations(lst, length)]\n",
    "    els =  list(itertools.product(lst,repeat = length))\n",
    "    els = [' '.join(tups) for tups in els]\n",
    "    return els \n",
    "\n",
    "\n",
    "def get_all_combs(seq,power):\n",
    "  ret_comb=[]\n",
    "  c1=combinations_with_replacement(seq,power)\n",
    "  # lst = [word for word in c1]\n",
    "  # print(len(lst))\n",
    "  for c in c1:\n",
    "    p=permutations(c,power)\n",
    "    new_list=[]\n",
    "    lst=list(p)\n",
    "    for tup in lst:\n",
    "      str_new =  ''.join(tup) \n",
    "      new_list.append(str_new)\n",
    "    unique_list=np.unique(new_list)\n",
    "    for u in unique_list:\n",
    "      ret_comb.append(u)\n",
    "  return ret_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AKztITEj4HVM",
    "outputId": "ea5140d7-3100-49d8-caf2-5147d00fc4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30112\n"
     ]
    }
   ],
   "source": [
    "length_max=0\n",
    "for i in range(0,len(train_sequences)):\n",
    "  k_mer_list=get_motifs(K_MER_LENGTH,train_sequences[i])\n",
    "  if len(k_mer_list)>length_max:\n",
    "    length_max=len(k_mer_list)\n",
    "print(length_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caEOy92RBTQd"
   },
   "outputs": [],
   "source": [
    "MAX_LEN=length_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BRGoLzmZgsZm",
    "outputId": "a49ba199-4695-4fe9-e13a-2bef65589253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 25, 'ATG': 20, 'ACA': 5, 'AAA': 0, 'ATC': 14, 'AAC': 4, 'ATA': 2, 'AGG': 34, 'CCT': 44, 'CTC': 45, 'AGC': 29, 'AAG': 7, 'AGA': 8, 'CAT': 15, 'AAT': 1, 'ATT': 10, 'CTG': 48, 'CTA': 16, 'ACT': 13, 'CAC': 26, 'ACG': 28, 'CAA': 6, 'AGT': 19, 'CCA': 27, 'CCG': 57, 'CCC': 56, 'CTT': 38, 'TAT': 11, 'GGT': 53, 'TGT': 42, 'CGA': 31, 'CAG': 30, 'TCT': 39, 'GAT': 21, 'CGG': 60, 'TTT': 37, 'TGC': 52, 'GGG': 63, 'TAG': 23, 'GGA': 36, 'TAA': 3, 'GGC': 62, 'TAC': 17, 'GAG': 35, 'TCG': 51, 'TTA': 12, 'GAC': 32, 'TCC': 46, 'GAA': 9, 'TCA': 18, 'GCA': 33, 'GTA': 22, 'GCC': 59, 'GTC': 50, 'GCG': 61, 'GTG': 54, 'TTC': 40, 'GTT': 41, 'GCT': 49, 'TGA': 24, 'TTG': 43, 'CGT': 47, 'TGG': 55, 'CGC': 58}\n"
     ]
    }
   ],
   "source": [
    "all_combination_list=get_all_combs('ATCG',K_MER_LENGTH)\n",
    "all_comb_dict={}\n",
    "for i in range(0,len(all_combination_list)):\n",
    "  all_comb_dict[all_combination_list[i]]=i\n",
    "print(all_comb_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G7sAL4OG2uYZ",
    "outputId": "8f25df95-8ecf-460d-c3ca-461fe327e235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(all_combination_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GSg5hIrC_e6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def one_hot_encode(d): #Pass the motif dictionary\n",
    "    S = pd.Series({'A':list(d.keys())})\n",
    "    # print(S)\n",
    "    one_hot = pd.get_dummies(S['A'])\n",
    "    print(type(one_hot))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rOKB79Ud9gZ-",
    "outputId": "048dd9f6-a00a-45f7-de51-f5900a1624da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "one_hot_df=one_hot_encode(all_comb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCIAKN0P-Ep5"
   },
   "outputs": [],
   "source": [
    "def get_max_len(all_seq_list):\n",
    "  max_len=0\n",
    "  for i in range(0,len(all_seq_list)):\n",
    "    lst=all_seq_list[i]\n",
    "    if len(lst)>max_len:\n",
    "      max_len=len(lst)\n",
    "  return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfD3A37miyY_"
   },
   "outputs": [],
   "source": [
    "def sequence_generator(all_seq_list,max_len, all_comb_dict,bs, y_vals):\n",
    "  num=0\n",
    "  while True:\n",
    "    sequences_2D_Mats=[]\n",
    "    indicators=[]\n",
    "    while len(indicators)<bs:\n",
    "      sequence=all_seq_list[num]      \n",
    "      sequence_k_mers=get_motifs(K_MER_LENGTH,sequence)\n",
    "      #print(len(sequence_k_mers))\n",
    "      Mat_2D=np.zeros((NUMBER_OF_K_MERS,max_len))\n",
    "      for col_val in range(0,len(sequence_k_mers)):\n",
    "        k_mer=sequence_k_mers[col_val]\n",
    "        row_value=all_comb_dict[k_mer]\n",
    "        Mat_2D[row_value,col_val]=1\n",
    "      sequences_2D_Mats.append(Mat_2D)\n",
    "      indicators.append(y_vals[num])\n",
    "      num+=1\n",
    "      if num==len(all_seq_list):\n",
    "        print(num)\n",
    "        num=0\n",
    "    yield (np.array(sequences_2D_Mats),indicators)\n",
    "    \n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVy7QWDJ3I_v"
   },
   "outputs": [],
   "source": [
    "train_sequences=np.array(train_sequences)\n",
    "y_indicator=np.array(y_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ewjjca7YwS0s",
    "outputId": "e5f628d9-5427-4a64-9118-65b8d6695f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6893,)\n",
      "(1217,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "train_sequences, y_indicator, test_size=0.15, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2Bmib6-zelm"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 150\n",
    "BS = 10\n",
    "Total_Epochs_Running=150\n",
    "\n",
    "\n",
    "LOSS_FN = 'binary_crossentropy'  \n",
    "LEARNING_RATE = 0.000001   # 0.0001, 0.00005, 0.00003\n",
    "\n",
    "\n",
    "\n",
    "num_train_seq=len(X_train)\n",
    "num_valid_seq=len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-zF1fzvyt1BS",
    "outputId": "2ed93d45-8963-47e7-a787-96acc4bb1204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "max_len=MAX_LEN\n",
    "print(type(all_comb_dict))\n",
    "trainGen = sequence_generator(X_train,max_len, all_comb_dict,BS,y_train)\n",
    "validationGen = sequence_generator(X_val,max_len, all_comb_dict,BS,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tScmnJFW7fAm"
   },
   "outputs": [],
   "source": [
    "def AlexNet(d1,d2):\n",
    "  model = Sequential()\n",
    "\n",
    "  # 1st Convolutional Layer\n",
    "  model.add(Conv1D(filters=96, input_shape=(d1,d2), kernel_size=11, strides=4, padding=\"valid\", activation = \"relu\"))\n",
    "\n",
    "  # Max Pooling\n",
    "  model.add(MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "\n",
    "  # 2nd Convolutional Layer\n",
    "  model.add(Conv1D(filters=256, kernel_size=5, strides=1, padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "  # Max Pooling\n",
    "  model.add(MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "\n",
    "  # 3rd Convolutional Layer\n",
    "  model.add(Conv1D(filters=384, kernel_size=3, strides=1, padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "  # 4th Convolutional Layer\n",
    "  model.add(Conv1D(filters=384, kernel_size=3, strides=1, padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "  # 5th Convolutional Layer\n",
    "  model.add(Conv1D(filters=256, kernel_size=3, strides=1, padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "  # Max Pooling\n",
    "  model.add(MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "\n",
    "  # Passing it to a Fully Connected layer\n",
    "  model.add(Flatten())\n",
    "  # 1st Fully Connected Layer\n",
    "  model.add(Dense(units = 9216, activation = \"relu\"))\n",
    "\n",
    "  # 2nd Fully Connected Layer\n",
    "  model.add(Dense(units = 4096, activation = \"relu\"))\n",
    "\n",
    "  # 3rd Fully Connected Layer\n",
    "  model.add(Dense(4096, activation = \"relu\"))\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(Dense(1, activation = \"sigmoid\")) \n",
    "\n",
    "  model.compile(loss=LOSS_FN, optimizer=Adam(lr=LEARNING_RATE), metrics=['accuracy'])\n",
    "  model.summary()\n",
    "\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv1D(f1, 1, padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv1D(f2_in, 1, padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv1D(f2_out, 3, padding='same', activation='relu')(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv1D(f3_in, 1,padding='same', activation='relu')(layer_in)\n",
    "    conv5 = Conv1D(f3_out, 5, padding='same', activation='relu')(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPool1D(3, strides=1, padding='same')(layer_in)\n",
    "    pool = Conv1D(f4_out, 1, padding='same', activation='relu')(pool)\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "\n",
    "    return layer_out\n",
    " \n",
    "def InceptionNet(dim1,dim2):\n",
    "    # define model input\n",
    "    visible = Input(shape=(dim1,dim2))\n",
    "    # add inception block 1\n",
    "    layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
    "    # add inception block 1\n",
    "    layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
    "    # create model\n",
    "\n",
    "    x = Flatten()(layer)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=visible, outputs=predictions)\n",
    "    model.compile(loss=LOSS_FN, optimizer=Adam(lr=LEARNING_RATE, amsgrad=True), metrics=['accuracy'])\n",
    "    # summarize model\n",
    "    model.summary()\n",
    "    return model\n",
    "    # plot model architecture\n",
    "    # plot_model(model, show_shapes=True, to_file='inception_module.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AlexNet(NUMBER_OF_K_MERS,MAX_LEN)\n",
    "model_name=\"AlexNet\"\n",
    "\n",
    "model_name=\"InceptionNet\"\n",
    "model=InceptionNet(NUMBER_OF_K_MERS,MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        # filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        filepath='Checkpoints/best_model_'+str(K_MER_LENGTH)+'_'+model_name+'_BS_'+str(BS)+'_E_'+str(Total_Epochs_Running)+'.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    # EarlyStopping(monitor='val_loss',mode='min', patience=200)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "Z13f3WS6vuui",
    "outputId": "bfbb6c30-7ed0-47bd-e62a-b2541ed5b453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "666/689 [===========================>..] - ETA: 10s - loss: 0.6182 - accuracy: 0.67706893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.6179 - accuracy: 0.67701217\n",
      "689/689 [==============================] - 366s 531ms/step - loss: 0.6178 - accuracy: 0.6772 - val_loss: 0.6545 - val_accuracy: 0.6702\n",
      "Epoch 2/10\n",
      "667/689 [============================>.] - ETA: 10s - loss: 0.6015 - accuracy: 0.68076893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.68101217\n",
      "689/689 [==============================] - 365s 530ms/step - loss: 0.6012 - accuracy: 0.6808 - val_loss: 0.5013 - val_accuracy: 0.6744\n",
      "Epoch 3/10\n",
      "667/689 [============================>.] - ETA: 10s - loss: 0.5902 - accuracy: 0.68506893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.68521217\n",
      "689/689 [==============================] - 369s 535ms/step - loss: 0.5897 - accuracy: 0.6853 - val_loss: 0.5878 - val_accuracy: 0.6802\n",
      "Epoch 4/10\n",
      "667/689 [============================>.] - ETA: 10s - loss: 0.5811 - accuracy: 0.68596893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.68601217\n",
      "689/689 [==============================] - 369s 536ms/step - loss: 0.5808 - accuracy: 0.6861 - val_loss: 0.5622 - val_accuracy: 0.6826\n",
      "Epoch 5/10\n",
      "668/689 [============================>.] - ETA: 9s - loss: 0.5731 - accuracy: 0.6909 6893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.69101217\n",
      "689/689 [==============================] - 371s 538ms/step - loss: 0.5727 - accuracy: 0.6910 - val_loss: 0.6505 - val_accuracy: 0.6826\n",
      "Epoch 6/10\n",
      "668/689 [============================>.] - ETA: 11s - loss: 0.5658 - accuracy: 0.69226893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5655 - accuracy: 0.69241217\n",
      "689/689 [==============================] - 428s 621ms/step - loss: 0.5655 - accuracy: 0.6925 - val_loss: 0.5753 - val_accuracy: 0.6826\n",
      "Epoch 7/10\n",
      "668/689 [============================>.] - ETA: 10s - loss: 0.5588 - accuracy: 0.69396893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.69401217\n",
      "689/689 [==============================] - 402s 583ms/step - loss: 0.5586 - accuracy: 0.6939 - val_loss: 0.5410 - val_accuracy: 0.6851\n",
      "Epoch 8/10\n",
      "668/689 [============================>.] - ETA: 12s - loss: 0.5526 - accuracy: 0.69636893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.69611217\n",
      "689/689 [==============================] - 457s 663ms/step - loss: 0.5525 - accuracy: 0.6959 - val_loss: 0.5873 - val_accuracy: 0.7083\n",
      "Epoch 9/10\n",
      "669/689 [============================>.] - ETA: 10s - loss: 0.5469 - accuracy: 0.69996893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5468 - accuracy: 0.70031217\n",
      "689/689 [==============================] - 405s 588ms/step - loss: 0.5466 - accuracy: 0.7004 - val_loss: 0.6451 - val_accuracy: 0.7182\n",
      "Epoch 10/10\n",
      "669/689 [============================>.] - ETA: 10s - loss: 0.5414 - accuracy: 0.70466893\n",
      "688/689 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.70511217\n",
      "689/689 [==============================] - 391s 568ms/step - loss: 0.5413 - accuracy: 0.7052 - val_loss: 0.4906 - val_accuracy: 0.7446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch=num_train_seq // BS,\n",
    "    validation_data=validationGen,\n",
    "    validation_steps=num_valid_seq // BS,\n",
    "    epochs=NUM_EPOCHS,\n",
    " callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AXGk6LB6LFR"
   },
   "outputs": [],
   "source": [
    "model.save(model_name+\"_K_\"+str(K_MER_LENGTH)+'_BS_'+str(BS)+'_E_'+str(Total_Epochs_Running)+'.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Covid19-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
