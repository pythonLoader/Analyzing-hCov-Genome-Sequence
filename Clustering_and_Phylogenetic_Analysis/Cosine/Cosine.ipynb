{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(input_file):\n",
    "    (seq, sequences_list)=('',[])\n",
    "    for line in open(input_file):\n",
    "        if line.startswith('>'):\n",
    "            sequences_list.append(seq)\n",
    "            seq = ''\n",
    "        else:\n",
    "            seq+= line.rstrip()\n",
    "    sequences_list.append(seq)\n",
    "    del sequences_list[0]\n",
    "    return sequences_list\n",
    "\n",
    "def get_motifs(length,sequences_list):\n",
    "    (d,index) = ({}, 0)\n",
    "    for seq in sequences_list:\n",
    "        for i in range(0, len(seq)-length+1):\n",
    "            word = seq[i:i+length]\n",
    "            if word not in d:\n",
    "                d[word] = index\n",
    "                index += 1 \n",
    "    return d\n",
    "\n",
    "def get_headers(input_file):\n",
    "    list_of_ids=[]\n",
    "    for line in open(input_file):\n",
    "        if line.startswith('>'):\n",
    "            line = line.replace('>','').split()\n",
    "            list_of_ids.append(line[0])\n",
    "    return list_of_ids\n",
    "\n",
    "def calculate_occurrences(length, input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    sequences_list = df[\"Sequence\"]  #get_sequences(input_file)\n",
    "    d = get_motifs(length,sequences_list)\n",
    "    print(\"Done with motif finding\")   \n",
    "    rows_num = len(sequences_list)\n",
    "    cols_num = len(d)\n",
    "    data = np.zeros(shape=(rows_num,cols_num))\n",
    "    for row_idx, seq in enumerate(sequences_list):\n",
    "        for i in range(0, len(seq)-length+1):\n",
    "            word = seq[i:i+length]\n",
    "            col_idx = d[word]\n",
    "            data[row_idx, col_idx] += 1\n",
    "    return data\n",
    "\n",
    "def calculate_frequencies(occurrences_list,seqs_number):\n",
    "    frequencies_list =[]\n",
    "    for i in range(0,seqs_number):\n",
    "        frequencies_list.append(occurrences_list[i,:]/np.sum(occurrences_list[i,:]))\n",
    "    return np.vstack(frequencies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski(list_,seqs_number,exponent): \n",
    "    matrix = np.zeros([seqs_number, seqs_number])\n",
    "    for i, j in itertools.combinations(range(0,seqs_number),2):\n",
    "         matrix[i][j]= matrix [j][i] = np.linalg.norm((list_[i,:]-list_[j,:]),ord=exponent)\n",
    "        #  (np.sum((np.absolute(list_[i,:] - list_[j,:]))**exponent))**(1.0/float(exponent))\n",
    "    return matrix\n",
    "def euclidean(list_,seqs_number):\n",
    "    return minkowski(list_,seqs_number,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Started working with -> Finland.csv\nn_seq-> (40,)\n0\n(40, 18)\n(40, 40)\nStarted working with -> Luxembourg.csv\nn_seq-> (86,)\n0\n(86, 18)\n(86, 86)\nStarted working with -> Algeria.csv\nn_seq-> (3,)\n0\n(3, 18)\n(3, 3)\nStarted working with -> Argentina.csv\nn_seq-> (3,)\n0\n(3, 18)\n(3, 3)\nStarted working with -> Australia.csv\nn_seq-> (1045,)\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n(1045, 18)\n(1045, 1045)\nStarted working with -> Austria.csv\nn_seq-> (21,)\n0\n(21, 18)\n(21, 21)\nStarted working with -> Bangladesh.csv\nn_seq-> (7,)\n0\n(7, 18)\n(7, 7)\nStarted working with -> Belarus.csv\nn_seq-> (2,)\n0\n(2, 18)\n(2, 2)\nStarted working with -> Belgium.csv\nn_seq-> (386,)\n0\n100\n200\n300\n(386, 18)\n(386, 386)\nStarted working with -> Brazil.csv\nn_seq-> (34,)\n0\n(34, 18)\n(34, 34)\nStarted working with -> Cambodia.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Canada.csv\nn_seq-> (130,)\n0\n100\n(130, 18)\n(130, 130)\nStarted working with -> Chile.csv\nn_seq-> (7,)\n0\n(7, 18)\n(7, 7)\nStarted working with -> China.csv\nn_seq-> (310,)\n0\n100\n200\n300\n(310, 18)\n(310, 310)\nStarted working with -> Colombia.csv\nn_seq-> (2,)\n0\n(2, 18)\n(2, 2)\nStarted working with -> Czech Republic.csv\nn_seq-> (28,)\n0\n(28, 18)\n(28, 28)\nStarted working with -> Democratic Republic of the Congo.csv\nn_seq-> (38,)\n0\n(38, 18)\n(38, 38)\nStarted working with -> Denmark.csv\nn_seq-> (9,)\n0\n(9, 18)\n(9, 9)\nStarted working with -> Ecuador.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> England.csv\nn_seq-> (2317,)\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n(2317, 18)\n(2317, 2317)\nStarted working with -> Estonia.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> France.csv\nn_seq-> (226,)\n0\n100\n200\n(226, 18)\n(226, 226)\nStarted working with -> Georgia.csv\nn_seq-> (28,)\n0\n(28, 18)\n(28, 28)\nStarted working with -> Germany.csv\nn_seq-> (86,)\n0\n(86, 18)\n(86, 86)\nStarted working with -> Ghana.csv\nn_seq-> (6,)\n0\n(6, 18)\n(6, 6)\nStarted working with -> Greece.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> Hong Kong.csv\nn_seq-> (62,)\n0\n(62, 18)\n(62, 62)\nStarted working with -> Hungary.csv\nn_seq-> (3,)\n0\n(3, 18)\n(3, 3)\nStarted working with -> Iceland.csv\nn_seq-> (565,)\n0\n100\n200\n300\n400\n500\n(565, 18)\n(565, 565)\nStarted working with -> India.csv\nn_seq-> (41,)\n0\n(41, 18)\n(41, 41)\nStarted working with -> Iran.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Ireland.csv\nn_seq-> (14,)\n0\n(14, 18)\n(14, 14)\nStarted working with -> Israel.csv\nn_seq-> (2,)\n0\n(2, 18)\n(2, 2)\nStarted working with -> Italy.csv\nn_seq-> (39,)\n0\n(39, 18)\n(39, 39)\nStarted working with -> Japan.csv\nn_seq-> (102,)\n0\n100\n(102, 18)\n(102, 102)\nStarted working with -> Korea.csv\nn_seq-> (36,)\n0\n(36, 18)\n(36, 36)\nStarted working with -> Kuwait.csv\nn_seq-> (8,)\n0\n(8, 18)\n(8, 8)\nStarted working with -> Latvia.csv\nn_seq-> (10,)\n0\n(10, 18)\n(10, 10)\nStarted working with -> Lithuania.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Malaysia.csv\nn_seq-> (10,)\n0\n(10, 18)\n(10, 10)\nStarted working with -> Mexico.csv\nn_seq-> (14,)\n0\n(14, 18)\n(14, 14)\nStarted working with -> Nepal.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Netherlands.csv\nn_seq-> (567,)\n0\n100\n200\n300\n400\n500\n(567, 18)\n(567, 567)\nStarted working with -> New Zealand.csv\nn_seq-> (8,)\n0\n(8, 18)\n(8, 8)\nStarted working with -> Nigeria.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Norway.csv\nn_seq-> (26,)\n0\n(26, 18)\n(26, 26)\nStarted working with -> Pakistan.csv\nn_seq-> (2,)\n0\n(2, 18)\n(2, 2)\nStarted working with -> Panama.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Peru.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Poland.csv\nn_seq-> (7,)\n0\n(7, 18)\n(7, 7)\nStarted working with -> Portugal.csv\nn_seq-> (100,)\n0\n(100, 18)\n(100, 100)\nStarted working with -> Qatar.csv\nn_seq-> (10,)\n0\n(10, 18)\n(10, 10)\nStarted working with -> Ref_seq.csv\nn_seq-> (1,)\n0\n(1, 18)\n(1, 1)\nStarted working with -> Russia.csv\nn_seq-> (38,)\n0\n(38, 18)\n(38, 38)\nStarted working with -> Saudi Arabia.csv\nn_seq-> (3,)\n0\n(3, 18)\n(3, 3)\nStarted working with -> Senegal.csv\nn_seq-> (22,)\n0\n(22, 18)\n(22, 22)\nStarted working with -> Singapore.csv\nn_seq-> (45,)\n0\n(45, 18)\n(45, 45)\nStarted working with -> Slovakia.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> Slovenia.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> South Africa.csv\nn_seq-> (6,)\n0\n(6, 18)\n(6, 6)\nStarted working with -> South Korea.csv\nn_seq-> (33,)\n0\n(33, 18)\n(33, 33)\nStarted working with -> Spain.csv\nn_seq-> (145,)\n0\n100\n(145, 18)\n(145, 145)\nStarted working with -> Sweden.csv\nn_seq-> (4,)\n0\n(4, 18)\n(4, 4)\nStarted working with -> Switzerland.csv\nn_seq-> (48,)\n0\n(48, 18)\n(48, 48)\nStarted working with -> Taiwan.csv\nn_seq-> (61,)\n0\n(61, 18)\n(61, 61)\nStarted working with -> Thailand.csv\nn_seq-> (7,)\n0\n(7, 18)\n(7, 7)\nStarted working with -> Turkey.csv\nn_seq-> (5,)\n0\n(5, 18)\n(5, 5)\nStarted working with -> United Kingdom.csv\nn_seq-> (3097,)\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n(3097, 18)\n(3097, 3097)\nStarted working with -> Uruguay.csv\nn_seq-> (9,)\n0\n(9, 18)\n(9, 9)\nStarted working with -> USA.csv\nn_seq-> (2378,)\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n(2378, 18)\n(2378, 2378)\nStarted working with -> Vietnam.csv\nn_seq-> (8,)\n0\n(8, 18)\n(8, 8)\n"
    }
   ],
   "source": [
    "files = os.listdir('All_Countries_Splitted')\n",
    "main_dir = 'All_Countries_Splitted'\n",
    "if not os.path.exists(\"All_Countries_Spectral_Vects\"):\n",
    "    os.mkdir(\"All_Countries_Spectral_Vects\")\n",
    "if not os.path.exists(\"All_Countries_Distance_Matrix\"):\n",
    "    os.mkdir(\"All_Countries_Distance_Matrix\")\n",
    "\n",
    "# NFV_Vects = os.listdir(\"All_Countries_NFV_Vects\")\n",
    "# contries_ = []\n",
    "# for fl in NFV_Vects:\n",
    "#     contries_.append(fl.split(\"_\")[0])\n",
    "\n",
    "for file_ in files:\n",
    "    \n",
    "    inp_file = main_dir + \"/\"+file_\n",
    "    c_name = file_.split(\".\")[0]\n",
    "    # if(c_name in contries_):\n",
    "    #     continue\n",
    "    df = pd.read_csv(inp_file)\n",
    "    \n",
    "    \n",
    "    print(\"Started working with ->\",file_)\n",
    "    sequences = df[\"Sequence\"]\n",
    "    print(\"n_seq->\",sequences.shape)\n",
    "    final_list = []\n",
    "    count = 0\n",
    "    # for seq in sequences:\n",
    "    final_list = calculate_occurrences(length=3,inp_file)\n",
    "    #     n_seq = encode()\n",
    "    # for seq in sequences:\n",
    "    #     Fast_vector = get_NFV(seq)\n",
    "    #     final_list.append(Fast_vector)\n",
    "    #     if(count%100 == 0):\n",
    "    #         print(count)\n",
    "    #     count +=1\n",
    "        # print(Fast_vector)\n",
    "    \n",
    "    acc_vects = cont_ = np.array(final_list)\n",
    "    print(acc_vects.shape)\n",
    "    # cont_ = np.array(acc_vects)\n",
    "    # print(cont_.shape)\n",
    "    ID_arr = df[\"Accession ID\"]\n",
    "    # print(ID_arr.shape)\n",
    "    ID_col = pd.Series(ID_arr)\n",
    "    Vector_col = pd.Series(cont_.tolist())\n",
    "    frame = {'Accession ID': ID_col,'Spectral Vector':Vector_col}\n",
    "    df_final = pd.DataFrame(frame)\n",
    "    direc_1 = \"All_Countries_Spectral_Vects\"\n",
    "    df_final.to_csv(direc_1+\"/\"+c_name+\"_Euclidean.csv\",index=False)\n",
    "    direc_2 = \"All_Countries_Distance_Matrix\"\n",
    "    matrix = euclidean(cont_,len(cont_))\n",
    "    print(matrix.shape)\n",
    "    final_df = pd.DataFrame(matrix,columns=ID_arr)\n",
    "    final_df.to_csv(direc_2+\"/\"+c_name+\"_accumulated_distance_matrix.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_file = \"Others_Af_CA_SA.csv\" #Test_gisaid_LS.csv/Train_gisaid_LS.csv\n",
    "# length = sys.argv[2]\n",
    "df = pd.read_csv(inp_file)\n",
    "\n",
    "\n",
    "sequences = df[\"Sequence\"]\n",
    "# seq = sequences[0]\n",
    "c_name = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(137, 18)\n(137,)\n"
    }
   ],
   "source": [
    "cont_ = np.array(final_list)\n",
    "print(cont_.shape)\n",
    "ID_arr = df[\"Accession ID\"]\n",
    "print(ID_arr.shape)\n",
    "\n",
    "ID_col = pd.Series(ID_arr)\n",
    "Vector_col = pd.Series(cont_.tolist())\n",
    "\n",
    "frame = {'Accession ID': ID_col,'Fast Vector':Vector_col}\n",
    "df_final = pd.DataFrame(frame)\n",
    "\n",
    "df_final.to_csv(c_name+\"_Fast_vector.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski(list_,seqs_number,exponent): \n",
    "    matrix = np.zeros([seqs_number, seqs_number])\n",
    "    for i, j in itertools.combinations(range(0,seqs_number),2):\n",
    "         matrix[i][j]= matrix [j][i] = np.linalg.norm((list_[i,:]-list_[j,:]),ord=exponent)\n",
    "        #  (np.sum((np.absolute(list_[i,:] - list_[j,:]))**exponent))**(1.0/float(exponent))\n",
    "    return matrix\n",
    "def euclidean(list_,seqs_number):\n",
    "    return minkowski(list_,seqs_number,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(137, 137)\n"
    }
   ],
   "source": [
    "matrix = euclidean(cont_,len(cont_))\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(matrix,columns=ID_arr)\n",
    "final_df.to_csv(c_name+\"_fast_distance_matrix.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the hell is this behaviour Puja?\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2069, 18)\n"
    }
   ],
   "source": [
    "Test_list = final_list.copy()\n",
    "Test_list = np.array(Test_list)\n",
    "print(Test_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(8110, 18)\n"
    }
   ],
   "source": [
    "Train_list = final_list.copy()\n",
    "Train_list = np.array(Train_list)\n",
    "print(Train_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10179, 18)\n"
    }
   ],
   "source": [
    "final = np.concatenate((Train_list,Test_list))\n",
    "Train_Id = df[\"Accession ID\"]\n",
    "\n",
    "print(final.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10179,)\n"
    }
   ],
   "source": [
    "Test_Id = df[\"Accession ID\"]\n",
    "\n",
    "ID_Final = np.concatenate((Train_Id,Test_Id))\n",
    "print(ID_Final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_col = pd.Series(ID_Final)\n",
    "Vector_col = pd.Series(final.tolist())\n",
    "\n",
    "frame = {'Accession ID': ID_col,'Fast Vector':Vector_col}\n",
    "df_final = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"Fast_Vector_GisAID.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bite0e3e371ce084a1196d49e0c40db08e6",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}