{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "working with-> Algeria\ncenter EPI_ISL_420037\nworking with-> Argentina\ncenter EPI_ISL_420600\nworking with-> Australia\ncenter EPI_ISL_426990\nworking with-> Austria\ncenter EPI_ISL_419662\nworking with-> Bangladesh\ncenter EPI_ISL_445214\nworking with-> Belarus\ncenter EPI_ISL_419693\nworking with-> Belgium\ncenter EPI_ISL_421188\nworking with-> Brazil\ncenter EPI_ISL_427305\nworking with-> Cambodia\ncenter EPI_ISL_411902\nworking with-> Canada\ncenter EPI_ISL_418344\nworking with-> Chile\ncenter EPI_ISL_414579\nworking with-> China\ncenter EPI_ISL_416473\nworking with-> Colombia\ncenter EPI_ISL_418262\nworking with-> Czech Republic\ncenter EPI_ISL_426887\nworking with-> Democratic Republic of the Congo\ncenter EPI_ISL_417441\nworking with-> Ecuador\ncenter EPI_ISL_422565\nworking with-> England\ncenter EPI_ISL_425337\nworking with-> Estonia\ncenter EPI_ISL_420066\nworking with-> Finland\ncenter EPI_ISL_418389\nworking with-> France\ncenter EPI_ISL_418429\nworking with-> Georgia\ncenter EPI_ISL_415644\nworking with-> Ghana\ncenter EPI_ISL_422394\nworking with-> Greece\ncenter EPI_ISL_418263\nworking with-> Hong Kong\ncenter EPI_ISL_417180\nworking with-> Hungary\ncenter EPI_ISL_418183\nworking with-> Iceland\ncenter EPI_ISL_424407\nworking with-> India\ncenter EPI_ISL_424362\nworking with-> Iran\ncenter EPI_ISL_424349\nworking with-> Ireland\ncenter EPI_ISL_418582\nworking with-> Israel\ncenter EPI_ISL_419210\nworking with-> Italy\ncenter EPI_ISL_418260\nworking with-> Japan\ncenter EPI_ISL_418809\nworking with-> Korea\ncenter EPI_ISL_412869\nworking with-> Kuwait\ncenter EPI_ISL_422426\nworking with-> Latvia\ncenter EPI_ISL_421656\nworking with-> Lithuania\ncenter EPI_ISL_416741\nworking with-> Luxembourg\ncenter EPI_ISL_419576\nworking with-> Malaysia\ncenter EPI_ISL_416886\nworking with-> Mexico\ncenter EPI_ISL_426365\nworking with-> Nepal\ncenter EPI_ISL_410301\nworking with-> Netherlands\ncenter EPI_ISL_414530\nworking with-> New Zealand\ncenter EPI_ISL_416538\nworking with-> Nigeria\ncenter EPI_ISL_413550\nworking with-> Norway\ncenter EPI_ISL_420137\nworking with-> Pakistan\ncenter EPI_ISL_417444\nworking with-> Denmark\ncenter EPI_ISL_415646\nworking with-> Germany\ncenter EPI_ISL_414508\nworking with-> Panama\ncenter EPI_ISL_415152\nworking with-> Singapore\ncenter EPI_ISL_422430\nworking with-> Switzerland\ncenter EPI_ISL_413019\nworking with-> Peru\ncenter EPI_ISL_415787\nworking with-> Poland\ncenter EPI_ISL_428236\nworking with-> Portugal\ncenter EPI_ISL_419386\nworking with-> Qatar\ncenter EPI_ISL_427419\nworking with-> Russia\ncenter EPI_ISL_415710\nworking with-> Saudi Arabia\ncenter EPI_ISL_416522\nworking with-> Senegal\ncenter EPI_ISL_420072\nworking with-> Slovakia\ncenter EPI_ISL_417877\nworking with-> Slovenia\ncenter EPI_ISL_426379\nworking with-> South Africa\ncenter EPI_ISL_421576\nworking with-> South Korea\ncenter EPI_ISL_412869\nworking with-> Spain\ncenter EPI_ISL_421520\nworking with-> Sweden\ncenter EPI_ISL_424703\nworking with-> Taiwan\ncenter EPI_ISL_415742\nworking with-> Thailand\ncenter EPI_ISL_423041\nworking with-> Turkey\ncenter EPI_ISL_424366\nworking with-> United Kingdom\ncenter EPI_ISL_422278\nworking with-> Uruguay\ncenter EPI_ISL_426479\nworking with-> USA\ncenter EPI_ISL_426080\nworking with-> Vietnam\ncenter EPI_ISL_418269\n(68, 7)\n"
    }
   ],
   "source": [
    "direc = 'All_Countries_Representative_Seq'\n",
    "Other_Info_File = \"All_Train_Test_Gisaid.csv\"\n",
    "\n",
    "ACC_VECTS_direc = 'All_Countries_Spectral_Vects'\n",
    "Other_Info_df = pd.read_csv(Other_Info_File)\n",
    "Other_Info_df_2 = pd.read_csv(\"gisaid_new_data.csv\")\n",
    "# ref_seq_df = pd.read_csv(\"All_Countries_Splitted/Ref_seq.csv\")\n",
    "df_list = []\n",
    "# cols = ['Country','Accession ID', 'Fast Vector', 'Virus name', 'Location',\n",
    "#        'Collection date', 'Death', 'Indicator', 'Sequence']\n",
    "cols = ['Country','Accession ID', 'Spectral Vector', 'Virus name', 'Location',\n",
    "       'Collection date', 'Sequence']\n",
    "for file_ in os.listdir(direc):\n",
    "    typ = file_.split(\".\")[1]\n",
    "    if(typ == 'txt'):\n",
    "        cont_ = file_.split(\"_\")[0]\n",
    "        print(\"working with->\",cont_)\n",
    "        Vect_file = ACC_VECTS_direc +\"/\"+cont_+\"_Euclidean.csv\"\n",
    "        c_fl = open(direc+\"/\"+file_,\"r\")\n",
    "        center_id = c_fl.read()\n",
    "        print(\"center\",center_id)\n",
    "        Fast_vector_df = pd.read_csv(Vect_file)\n",
    "\n",
    "        final_df_1 = Fast_vector_df.loc[Fast_vector_df[\"Accession ID\"] == center_id]\n",
    "        final_df_2 = Other_Info_df.loc[Other_Info_df[\"Accession ID\"] == center_id]\n",
    "        # print()\n",
    "        if(final_df_2.shape[0] == 0):\n",
    "            final_df_2 = Other_Info_df_2[Other_Info_df_2[\"Accession ID\"] == center_id]\n",
    "        # if(final_df_2.shape[0] == 0):\n",
    "        #     final_df_2 = ref_seq_df[ref_seq_df[\"Accession ID\"] == center_id]\n",
    "        if(cont_ == \"United Kingdom\" or cont_ == \"Korea\"):\n",
    "            continue\n",
    "        # frame = {'Accession ID':pd.Series(center_id),'Country':pd.Series(cont_)}\n",
    "        # final_df_3 = pd.DataFrame(frame)\n",
    "        # print(final_df_1.shape)\n",
    "        # print(final_df_2.shape)\n",
    "        final_df = pd.merge(final_df_1, final_df_2, on='Accession ID')\n",
    "        final_df[\"Country\"] = cont_\n",
    "        final_df = final_df[cols]\n",
    "        df_list.append(final_df)\n",
    "\n",
    "f_df = pd.concat(df_list,ignore_index=True)\n",
    "print(f_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['Country', 'Accession ID', 'Spectral Vector', 'Virus name', 'Location',\n       'Collection date', 'Sequence'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "print(f_df.columns)\n",
    "f_df.to_csv(\"All_country_representative_seq_info.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motifs(length,sequences_list):\n",
    "    (d,index) = ({}, 0)\n",
    "    for seq in sequences_list:\n",
    "        for i in range(0, len(seq)-length+1):\n",
    "            word = seq[i:i+length]\n",
    "            if word not in d:\n",
    "                d[word] = index\n",
    "                index += 1 \n",
    "    return d\n",
    "\n",
    "def calculate_occurrences(length, df):\n",
    "    # df = pd.read_csv(input_file)\n",
    "    sequences_list = df[\"Sequence\"]  #get_sequences(input_file)\n",
    "    d = get_motifs(length,sequences_list)\n",
    "    print(\"Done with motif finding\")   \n",
    "    rows_num = len(sequences_list)\n",
    "    cols_num = len(d)\n",
    "    data = np.zeros(shape=(rows_num,cols_num))\n",
    "    for row_idx, seq in enumerate(sequences_list):\n",
    "        for i in range(0, len(seq)-length+1):\n",
    "            word = seq[i:i+length]\n",
    "            col_idx = d[word]\n",
    "            data[row_idx, col_idx] += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_cos(i,j,list_):\n",
    "    return np.sum(list_[i,:] * list_[j,:])/(np.sqrt(np.sum(list_[i,:]**2)) * np.sqrt(np.sum(list_[j,:]**2)))\n",
    "\n",
    "def cosine(list_, seqs_number):\n",
    "    matrix = np.zeros([seqs_number, seqs_number])\n",
    "    for i, j in itertools.combinations(range(0,seqs_number),2):\n",
    "         matrix[i][j] = matrix[j][i] = (1 - angle_cos(i,j,list_)).round(10) + 0.0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "68\nDone with motif finding\n[[1. 1. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 1. 1. 1.]]\n['Algeria' 'Argentina' 'Australia' 'Austria' 'Bangladesh' 'Belarus'\n 'Belgium' 'Brazil' 'Cambodia' 'Canada' 'Chile' 'China' 'Colombia'\n 'Czech Republic' 'Democratic Republic of the Congo' 'Ecuador' 'England'\n 'Estonia' 'Finland' 'France' 'Georgia' 'Ghana' 'Greece' 'Hong Kong'\n 'Hungary' 'Iceland' 'India' 'Iran' 'Ireland' 'Israel' 'Italy' 'Japan'\n 'Kuwait' 'Latvia' 'Lithuania' 'Luxembourg' 'Malaysia' 'Mexico' 'Nepal'\n 'Netherlands' 'New Zealand' 'Nigeria' 'Norway' 'Pakistan' 'Denmark'\n 'Germany' 'Panama' 'Singapore' 'Switzerland' 'Peru' 'Poland' 'Portugal'\n 'Qatar' 'Russia' 'Saudi Arabia' 'Senegal' 'Slovakia' 'Slovenia'\n 'South Africa' 'South Korea' 'Spain' 'Sweden' 'Taiwan' 'Thailand'\n 'Turkey' 'Uruguay' 'USA' 'Vietnam']\n(68, 69)\n"
    }
   ],
   "source": [
    "f_df = pd.read_csv(\"All_country_representative_seq_info.csv\")\n",
    "def all_country_distance_table():\n",
    "    vect = f_df['Spectral Vector']\n",
    "    cont_ = f_df['Country']\n",
    "    final_vect_len = f_df.shape[0]\n",
    "    print(final_vect_len)\n",
    "    # final_vect = np.full((final_vect_len,final_vect_len),-89)\n",
    "    list_ = []\n",
    "    # for i in range(final_vect_len):\n",
    "    #     var_1 = np.asarray(vect[i].replace('\"',\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(' ','').split(\",\")).astype(np.float)\n",
    "    #     list_.append(var_1)\n",
    "    list_ = calculate_occurrences(final_vect_len,f_df)\n",
    "    print(list_)\n",
    "    final_vect = cosine(list_,final_vect_len)\n",
    "        # for j in range(final_vect_len):\n",
    "        #     # print(\"Doing -> \",cont_[i],cont_[j])\n",
    "        #     var_1 = \n",
    "        #     var_2 = np.asarray(vect[j].replace('\"',\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(' ','').split(\",\")).astype(np.float)\n",
    "        #     final_vect[i][j] = (1-(np.sum(var_1 * var_2)/(np.sqrt(np.sum(var_1**2)) * np.sqrt(var_2**2)))).round(10) + 0.0\n",
    "            # print(final_vect[i][j])\n",
    "\n",
    "    # print(final_vect)\n",
    "    return (np.array(cont_),final_vect)\n",
    "\n",
    "(cont_,final_vect) = all_country_distance_table()\n",
    "print(cont_)\n",
    "final_col = []\n",
    "final_col.append(\"\")\n",
    "final_col.extend(cont_)\n",
    "cont_ = cont_.reshape(cont_.shape[0],1)\n",
    "target = np.hstack((cont_, final_vect))\n",
    "print(target.shape)\n",
    "ekdom_final_df = pd.DataFrame(target,columns=final_col)\n",
    "# print(ekdom_final_df.shape)\n",
    "# ekdom_final_df.to_csv(\"Final_distance_matrix.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bite0e3e371ce084a1196d49e0c40db08e6",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}